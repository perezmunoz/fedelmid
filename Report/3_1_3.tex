%!TEX root = 0_architecture_rapport.tex

% subsection title
\subsection{Question 3}
\label{subsec:313}

% subsubsection title
\subsubsection{Question 3.a}
\label{subsubsec:313a}
\paragraph{}Using the links parser from the code written in Part 1 Question 2, the entire player database was parsed using BeautifulSoup and basic profile information was scraped from the website. A standard template was designed to hold variables such as \verb|playerid| (derived from the playerâ€™s HTML link was used as an unique identifier), name, positions, shooting hand, height, weight, birth date, city, state/country of birth, experience and death date. Where there are no values listed in the profile page, null values are assigned to the variables.

% subsubsection title
\subsubsection{Question 3.b}
\label{subsubsec:313b}

\paragraph{}The method used to scrap the basic statistics and salaries data is as follows:

\begin{itemize}
	\item \textbf{Scraping phase} by analyzing the structure of the tables (HTML tags) into .csv files
	\item Adding an unique \textbf{Player ID} at each table constructed as follows: \url{/players/b/bryanko01.html} becomes bbryanko01. Each player then can be accessed with its unique key
	\item \textbf{Cleaning phase} where some column's formats are modified so that they can be loaded and manipulated in the SQLite database
\end{itemize}

\paragraph{}Among all statistics of the basketball players, scraping some tables are sufficient to do the analysis requested in Part 2. The tables selected as player's statistics are below:

\begin{itemize}
	\item Totals
	\item Per Game
	%\item Per 36 Minute
	%\item Per 100 Poss
	%\item Advanced
	%\item Shooting
	%\item Play-by-Play
	%\item Playoffs Totals
	%\item Playoffs Per Game
	%\item Playoffs Per 36 Minute
	%\item Playoffs Per 100 Poss
	%\item Playoffs Advanced
	%\item Playoffs Shooting
	%\item Playoffs Play-by-Play
	%\item All-Star Games
	%\item Similarity Scores
	%\item Appareances on Leaderbords, Awards, and Honors
	%\item Transactions
	%\item Salaries
	%\item Contract
\end{itemize}

\paragraph{}These tables deal with statistics by season (Totals) and by game (Per Game) which is enough to conduct the requested analysis. However, since tables are not exactly identical (HTML tags), scraping them wasn't as easy as expected. Numerous specialties have had to be taken in consideration.

\paragraph{}As an example, here is referenced a special case encountered in Totals and Per Game tables when the player qualified to All-Star games. Next to the Season value, a star appears. Below the HTML code corresponding to the Totals table of Kobe Bryant.

\begin{minted}[frame=single,linenos,mathescape,fontsize=\small]{html}
<td align="left" >
	<a href="/players/b/bryanko01/gamelog/1998/">1997-98</a>
	<span class="bold_text" style="color:#c0c0c0">&nbsp;&#x2605;</span>
</td>
\end{minted}

\paragraph{}Scraping these web pages had been tricky in which the code should catch all these specialties. For further information about the code providing the player's statistics scraper, see the \verb|player_statistics_BS.py| file at \url{Code/BS/}.

\paragraph{}The output \verb|totals_final.csv| and \verb|per_game_final.csv| tables can be find in \url{Data/Part1/} folder.

% subsubsection title
\subsubsection{Question 3.c}
\label{subsubsec:313c}

\paragraph{}Scraping the player's salaries tables require to scrap two main tables:

\begin{itemize}
	\item Salaries (previous salaries)
	\item Contract (current and futures contracts if any)
\end{itemize}

\paragraph{}Thus, the method is to merge these two tables. Here again, some specialties on tables structure render the scraping tricky. Indeed, Contract table doesn't have a thead, tbody and tfoot tag. So its scraping is done differently. Furthermore, salary's format is \$15,000,000 for instance. Unchanged, salary cannot be loaded to the SQLite database. Dollar symbol and commas have been removed so that the new salary's format is 15000000 (Cleaning phase).

\paragraph{}The output \verb|salaries_final.csv| table can be find in \url{Data/Part1/} folder.

% subsubsection title
\subsubsection{Question 3.d}
\label{subsubsec:313d}
\paragraph{}Question 3.A (see \ref{subsubsec:313a}) can be repeated using Regex. A sample skeleton has been written (\verb|profile_parser_regex.py| in \url{Code/Part1/Regex/}) to parse the player profile using Regex. Using BeautifulSoup4 to parse seems to be easier because we can make use of existing methods to call various functions like \verb|soup.find|, \verb|soup.findNext| and \verb|soup.get_text|. Using these functions make the code more readable and easily understandable. It allows for easy debugging should the program break due to an uncaught exception. Regex tends to be more rigid and inflexible. BeautifulSoup4 allows us to traverse the parse tree to look for specific objects at specific part of the HTML document. With regex, we have to search the entire document for each search item. 

\paragraph{}We prefer to use BeautifulSoup4 to parse HTML and obtain the strings we are interested in. Then we can use regex to retrieve the information in those strings. We feel then that the best way is to use a combination of both.
